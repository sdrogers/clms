{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Varying N in top-N DDA fragmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VMSfunctions.Chemicals import *\n",
    "from VMSfunctions.Chromatograms import *\n",
    "from VMSfunctions.MassSpec import *\n",
    "from VMSfunctions.Controller import *\n",
    "from VMSfunctions.Common import *\n",
    "from VMSfunctions.DataGenerator import *\n",
    "from VMSfunctions.Noise import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is calculated by precision, recall and the mean square error of intensity when the fragmentation event occur to the maximum intensity of the chromatographic peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_chem(to_find, chem_list):\n",
    "#     for chem in chem_list:\n",
    "#         assert chem is not None\n",
    "#         assert to_find is not None\n",
    "#         if chem.max_intensity == to_find.max_intensity and \\\n",
    "#             chem.rt == to_find.rt and \\\n",
    "#             chem.chromatogram == to_find.chromatogram:\n",
    "#             return chem\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fragmented(chem, fragmented_chems):\n",
    "    peaks = fragmented_chems[chem]\n",
    "    ms_counts = defaultdict(int)\n",
    "    for p in peaks:\n",
    "        ms_counts[p.ms_level] += 1\n",
    "    return ms_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(chem):\n",
    "    return (tuple(chem.isotopes), chem.rt, chem.max_intensity)\n",
    "\n",
    "def get_frag_events(controller, ms_level):\n",
    "    filtered_frag_events = list(filter(lambda x: x.ms_level == ms_level, controller.mass_spec.fragmentation_events))\n",
    "    chem_to_frag_events = defaultdict(list)\n",
    "    for frag_event in filtered_frag_events:\n",
    "        key = get_key(frag_event.chem)\n",
    "        chem_to_frag_events[key].append(frag_event)\n",
    "    return dict(chem_to_frag_events)\n",
    "\n",
    "def count_frag_events(key, chem_to_frag_events):\n",
    "    chem_rt = key[1]\n",
    "    frag_events = chem_to_frag_events[key]\n",
    "    good_count = 0\n",
    "    bad_count = 0\n",
    "    for frag_event in frag_events:\n",
    "        rt_match = chem.chromatogram._rt_match(frag_event.query_rt - chem_rt)\n",
    "        if rt_match:\n",
    "            good_count += 1\n",
    "        else:\n",
    "            bad_count += 1\n",
    "    return good_count, bad_count\n",
    "\n",
    "def get_chem_frag_counts(chem_list, chem_to_frag_events):\n",
    "    results = {}\n",
    "    for i in range(len(chem_list)):\n",
    "        chem = chem_list[i]\n",
    "        key = get_key(chem)\n",
    "        try:\n",
    "            good_count, bad_count = count_frag_events(key, chem_to_frag_events)\n",
    "        except KeyError:\n",
    "            good_count = 0\n",
    "            bad_count = 0\n",
    "        results[chem] = {\n",
    "            'good': good_count, \n",
    "            'bad': bad_count\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance(controller, dataset):\n",
    "    ms_level = 2\n",
    "    chem_to_frag_events = get_frag_events(controller, ms_level)\n",
    "    positives = list(filter(lambda x: x.type == 'data', dataset))\n",
    "    negatives = list(filter(lambda x: x.type == 'noise', dataset))\n",
    "    positives_count = get_chem_frag_counts(positives, chem_to_frag_events)\n",
    "    negatives_count = get_chem_frag_counts(negatives, chem_to_frag_events)    \n",
    "\n",
    "    # count the following:\n",
    "    # true positive = is an xcms peak and is fragmented within the chemical's elution time\n",
    "    # false positive = is not an xcms peak and is fragmented within the chemical's elution time\n",
    "    # false negative = is an xcms peak and is not fragmented within the chemical's elution time\n",
    "\n",
    "    tp = len([chem for chem in positives if positives_count[chem]['good'] > 0])\n",
    "    fp = len([chem for chem in negatives if negatives_count[chem]['good'] > 0])\n",
    "    fn = len([chem for chem in positives if positives_count[chem]['good'] == 0])\n",
    "\n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    f1 = ( 2 * prec * rec) / (prec + rec)\n",
    "    prec, rec, f1\n",
    "    return tp, fp, fn, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_controller(results_dir, N, rt_tol):\n",
    "    analysis_name = 'experiment_N_%d_rttol_%d' % (N, rt_tol)    \n",
    "    pickle_in = '%s/%s.p' % (results_dir, analysis_name) \n",
    "    print('Loading %s' % analysis_name)                    \n",
    "    try:\n",
    "        controller = load_obj(pickle_in)\n",
    "    except FileNotFoundError:\n",
    "        controller = None\n",
    "    return controller\n",
    "\n",
    "def load_controllers(results_dir, Ns, rt_tols):\n",
    "    controllers = []\n",
    "    for N in Ns:\n",
    "        for rt_tol in rt_tols:\n",
    "            controller = load_controller(results_dir, N, rt_tol)\n",
    "            if controller is not None:\n",
    "                controllers.append(controller)\n",
    "    return controllers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../models/dda_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_obj('%s/noisy_dataset.p' % results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed rt_tol = 15 and varying Ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns = list(range(2, 101, 2))\n",
    "Ns = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "rt_tols = [15]\n",
    "controllers = load_controllers(results_dir, Ns, rt_tols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for controller in controllers:\n",
    "    N = controller.N\n",
    "    rt_tol = controller.rt_tol\n",
    "    tp, fp, fn, prec, rec, f1 = compute_performance(controller, dataset)      \n",
    "    print('N=%d rt_tol=%d tp=%d fp=%d fn=%d prec=%.3f rec=%.3f f1=%.3f' % (N, rt_tol, tp, fp, fn, prec, rec, f1))\n",
    "    res = (N, rt_tol, tp, fp, fn, prec, rec, f1)    \n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['N', 'rt_tol', 'TP', 'FP', 'FN', 'Prec', 'Rec', 'F1'])\n",
    "df.plot.line(x='N', y=['Prec'])\n",
    "plt.title('Precision vs N')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "df.plot.line(x='N', y=['Rec'])\n",
    "plt.title('Recall vs N')\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "df.plot.line(x='N', y=['F1'])\n",
    "plt.title('F1 vs N')\n",
    "plt.ylabel('F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed N = 10 and varying rt_tols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [10]\n",
    "rt_tols = list(range(15, 301, 15))\n",
    "controllers = load_controllers(results_dir, Ns, rt_tols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for controller in controllers:\n",
    "    N = controller.N\n",
    "    rt_tol = controller.rt_tol\n",
    "    tp, fp, fn, prec, rec, f1 = compute_performance(controller, dataset)      \n",
    "    print('N=%d rt_tol=%d tp=%d fp=%d fn=%d prec=%.3f rec=%.3f f1=%.3f' % (N, rt_tol, tp, fp, fn, prec, rec, f1))\n",
    "    res = (N, rt_tol, tp, fp, fn, prec, rec, f1)    \n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['N', 'rt_tol', 'TP', 'FP', 'FN', 'Prec', 'Rec', 'F1'])\n",
    "df.plot.line(x='N', y=['Prec'])\n",
    "plt.title('Precision vs N')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "df.plot.line(x='N', y=['Rec'])\n",
    "plt.title('Recall vs N')\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "df.plot.line(x='N', y=['F1'])\n",
    "plt.title('F1 vs N')\n",
    "plt.ylabel('F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute performance for varying Ns and rt_tols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "rt_tols = list(range(15, 301, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(Ns, rt_tols)\n",
    "Z_precision = np.zeros_like(X).astype(float)\n",
    "Z_recall = np.zeros_like(X).astype(float)\n",
    "Z_f1 = np.zeros_like(X).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(X.shape[1]):\n",
    "    for i in range(X.shape[0]):    \n",
    "        N = X[i, j]\n",
    "        rt_tol = Y[i, j]            \n",
    "        analysis_name = 'experiment_N_%d_rttol_%d' % (N, rt_tol)    \n",
    "        pickle_in = '%s/%s.p' % (results_dir, analysis_name) \n",
    "\n",
    "        print('Loading %s' % analysis_name)                    \n",
    "        try:\n",
    "            controller = load_obj(pickle_in)\n",
    "        except FileNotFoundError:\n",
    "            controller = None\n",
    "\n",
    "        # compute performance\n",
    "        if controller is not None:\n",
    "            tp, fp, fn, prec, rec, f1 = compute_performance(controller, dataset)\n",
    "            Z_precision[i, j] = prec\n",
    "            Z_recall[i, j] = rec\n",
    "            Z_f1[i, j] = f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {\n",
    "    'X': X,\n",
    "    'Y': Y,\n",
    "    'Z_precision': Z_precision,\n",
    "    'Z_recall': Z_recall,\n",
    "    'Z_f1': Z_f1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(plot_data, results_dir + '/plot_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(X, Y, Z, xlabel, ylabel, zlabel, title):\n",
    "    # Plot the surface.\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                           linewidth=0, antialiased=False)\n",
    "\n",
    "    # Customize the z axis.\n",
    "    # ax.set_zlim(-1.01, 1.01)\n",
    "    # ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    # ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_zlabel(zlabel)    \n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(X, Y, Z_precision, 'N', 'Dynamic exclusion window (s)', 'Precision', 'Precision with varying Ns and dynamic exclusion windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(X, Y, Z_recall, 'N', 'Dynamic exclusion window (s)', 'Recall', 'Recall with varying Ns and dynamic exclusion windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(X, Y, Z_f1, 'N', 'Dynamic exclusion window (s)', 'F_1', 'F_1 score with varying Ns and dynamic exclusion windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(X, Y, Z_precision, 'N', 'Dynamic exclusion window (s)', 'Precision', 'Precision with varying Ns and dynamic exclusion windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(X, Y, Z_recall, 'N', 'Dynamic exclusion window (s)', 'Recall', 'Recall with varying Ns and dynamic exclusion windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(X, Y, Z_f1, 'N', 'Dynamic exclusion window (s)', 'F_1', 'F_1 score with varying Ns and dynamic exclusion windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
